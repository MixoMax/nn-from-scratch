{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linus\\AppData\\Local\\Temp\\ipykernel_27436\\4233214276.py:19: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  y = torch.from_numpy(y)\n"
     ]
    }
   ],
   "source": [
    "X_path = \"./mnist_data/t10k-images.idx3-ubyte\"\n",
    "Y_path = \"./mnist_data/t10k-labels.idx1-ubyte\"\n",
    "\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "X = read_idx(X_path)\n",
    "y = read_idx(Y_path)\n",
    "\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "X = X.astype(np.float32) / 255\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "print(X.shape, y.shape)#\n",
    "\n",
    "X_train, X_test = X[:int(len(X)*0.8)], X[int(len(X)*0.8):]\n",
    "y_train, y_test = y[:int(len(y)*0.8)], y[int(len(y)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of neurons: 727,552\n"
     ]
    }
   ],
   "source": [
    "# very simple model\n",
    "input_size = 28*28\n",
    "n_labels = 10\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layers = [\n",
    "            torch.nn.Linear(input_size, 256),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.Linear(256, n_labels),\n",
    "        ]\n",
    "        self.model = torch.nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "print(model)\n",
    "n_neurons = sum([layer.weight.numel() for layer in model.layers])\n",
    "print(f\"Number of neurons: {n_neurons:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.27356645464897156\n",
      "Epoch 2/10, Loss: 0.20802274346351624\n",
      "Epoch 3/10, Loss: 0.24634283781051636\n",
      "Epoch 4/10, Loss: 0.2669011950492859\n",
      "Epoch 5/10, Loss: 0.3040083646774292\n",
      "Epoch 6/10, Loss: 0.3274763822555542\n",
      "Epoch 7/10, Loss: 0.30881571769714355\n",
      "Epoch 8/10, Loss: 0.2672855854034424\n",
      "Epoch 9/10, Loss: 0.27544105052948\n",
      "Epoch 10/10, Loss: 0.3405182361602783\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss.item()}\")\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1590.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(X_test), batch_size)):\n",
    "        X_batch = X_test[i:i+batch_size]\n",
    "        y_batch = y_test[i:i+batch_size]\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "        n_correct += (torch.argmax(y_pred, dim=1) == y_batch).sum().item()\n",
    "        n_total += len(y_batch)\n",
    "        \n",
    "print(f\"Accuracy: {n_correct/n_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test data as json\n"
     ]
    }
   ],
   "source": [
    "# save test data as json\n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump({\"X\": X_test.tolist(), \"y\": y_test.tolist()}, f)\n",
    "print(\"Saved test data as json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as JSON\n",
      "Number of neurons: 2,562,560\n"
     ]
    }
   ],
   "source": [
    "# save model as JSON\n",
    "import json\n",
    "model_dict = model.state_dict()\n",
    "for key in model_dict.keys():\n",
    "    model_dict[key] = model_dict[key].tolist()\n",
    "with open(\"model.json\", \"w\") as f:\n",
    "    json.dump(model_dict, f)\n",
    "print(\"Model saved as JSON\")\n",
    "n_neurons = sum([layer.weight.numel() for layer in model.layers])\n",
    "print(f\"Number of neurons: {n_neurons:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
